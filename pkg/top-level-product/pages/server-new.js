const express = require('express');
const cors = require('cors');
const axios = require('axios');
const { spawn } = require('child_process');
const path = require('path');

// Polyfill fetch cho Node.js versions cÅ©
try {
  // Thá»­ sá»­ dá»¥ng undici (preferred)
  const { fetch, Headers, Request, Response } = require('undici');
  if (!globalThis.fetch) {
    globalThis.fetch = fetch;
    globalThis.Headers = Headers;
    globalThis.Request = Request;
    globalThis.Response = Response;
  }
} catch (err) {
  // Fallback to node-fetch v2
  const fetch = require('node-fetch');
  if (!globalThis.fetch) {
    globalThis.fetch = fetch;
    globalThis.Headers = fetch.Headers;
    globalThis.Request = fetch.Request;
    globalThis.Response = fetch.Response;
  }
}

const OpenAI = require('openai');

const app = express();
app.use(cors());
app.use(express.json());

// Khá»Ÿi táº¡o OpenAI client
const openai = new OpenAI({
  baseURL: "http://192.168.10.32:11434/v1",
  apiKey: "ollama"
});

// MCP Server wrapper - Káº¿t ná»‘i vá»›i MCP server remote
class MCPServer {
  constructor() {
    this.serverUrl = process.env.MCP_SERVER_URL || 'http://192.168.10.18:3000'; // URL cá»§a MCP server (SSE mode)
    this.sseEndpoint = '/sse'; // SSE endpoint
    this.messagesEndpoint = '/messages'; // Messages endpoint
    this.sseEnabled = process.env.MCP_SSE_MODE === 'true'; // Flag Ä‘á»ƒ xÃ¡c Ä‘á»‹nh sá»­ dá»¥ng SSE hay STDIO
    this.isConnected = false;
  }

  // Káº¿t ná»‘i vá»›i MCP server remote
  async connect() {
    try {
      console.log('Trying to connect to MCP server at:', this.serverUrl);
      
      // For SSE MCP server, just test basic connectivity
      // The actual SSE connection will be established during tool calls
      const response = await axios.get(`${this.serverUrl}/`, {
        timeout: 5000,
        validateStatus: (status) => {
          // Accept any response that indicates server is running
          return status >= 200 && status < 500;
        }
      }).catch(async (rootError) => {
        // If root fails, try head request
        console.log('Root endpoint failed, trying HEAD request...');
        try {
          return await axios.head(this.serverUrl, { timeout: 5000 });
        } catch (headError) {
          throw rootError; // Throw original error
        }
      });
      
      if (response.status >= 200 && response.status < 500) {
        console.log('âœ… Connected to MCP Server (SSE ready)');
        this.isConnected = true;
        return true;
      } else {
        console.error('âŒ MCP Server connectivity check failed');
        this.isConnected = false;
        return false;
      }
    } catch (error) {
      console.error('âŒ Error connecting to MCP Server:', error.message);
      this.isConnected = false;
      return false;
    }
  }

  async callTool(toolName, params = {}) {
    try {
      if (!this.isConnected) {
        throw new Error('MCP Server not connected');
      }

      const request = {
        jsonrpc: "2.0",
        id: Date.now(),
        method: "tools/call",
        params: {
          name: toolName,
          arguments: params
        }
      };

      console.log('Sending to MCP:', JSON.stringify(request, null, 2));

      const response = await axios.post(`${this.serverUrl}${this.messagesEndpoint}`, request, {
        headers: {
          'Content-Type': 'application/json'
        },
        timeout: 30000,
        params: {
          sessionId: 'default-session' // SSE requires sessionId
        }
      });

      console.log('MCP Response:', JSON.stringify(response.data, null, 2));
      return response.data;

    } catch (error) {
      console.error('MCP Error:', error.response?.data || error.message);
      throw error;
    }
  }

  // Kiá»ƒm tra tráº¡ng thÃ¡i káº¿t ná»‘i
  isServerConnected() {
    return this.isConnected;
  }
}

const mcpServer = new MCPServer();

// Káº¿t ná»‘i MCP server khi khá»Ÿi Ä‘á»™ng
mcpServer.connect().then(() => {
  console.log('MCP Server connection initialized');
}).catch((error) => {
  console.error('Failed to initialize MCP Server connection:', error);
});

// OpenAI Structured Output Ä‘á»ƒ phÃ¢n tÃ­ch prompt thÃ nh JSON-RPC
async function analyzeWithOpenAI(userPrompt) {
  try {
    const systemPrompt = `Báº¡n lÃ  má»™t AI assistant chuyÃªn phÃ¢n tÃ­ch prompt Kubernetes vÃ  chuyá»ƒn Ä‘á»•i thÃ nh JSON-RPC format cho MCP server.

PhÃ¢n tÃ­ch prompt sau vÃ  xÃ¡c Ä‘á»‹nh:
1. Liá»‡u Ä‘Ã¢y cÃ³ pháº£i lÃ  Kubernetes command khÃ´ng
2. Tool nÃ o cáº§n sá»­ dá»¥ng (náº¿u lÃ  K8s command)
3. Arguments phÃ¹ há»£p cho tool Ä‘Ã³

CÃ¡c tool cÃ³ sáºµn:
- kubectl_get: láº¥y thÃ´ng tin resources (pods, deployments, services, etc.)
- kubectl_create: táº¡o resources (pods, deployments, services, etc.)
- kubectl_delete: xÃ³a resources
- kubectl_describe: mÃ´ táº£ chi tiáº¿t resources
- kubectl_logs: xem logs cá»§a pods
- kubectl_scale: scale deployments
- kubectl_rollout: quáº£n lÃ½ rollout

VÃ­ dá»¥ phÃ¢n tÃ­ch:
- "táº¡o pod nginx" â†’ isK8sCommand: true, tool: "kubectl_create", arguments: { resourceType: "pod", name: "nginx-pod", image: "nginx" }
- "xem pods" â†’ isK8sCommand: true, tool: "kubectl_get", arguments: { resourceType: "pods", namespace: "default" }
- "Hello world" â†’ isK8sCommand: false, tool: null, arguments: {}`;

    // Äá»‹nh nghÄ©a JSON Schema cho Structured Output
    const k8sAnalysisSchema = {
      type: "json_schema",
      json_schema: {
        name: "k8s_command_analysis",
        strict: true,
        schema: {
          type: "object",
          properties: {
            isK8sCommand: {
              type: "boolean",
              description: "XÃ¡c Ä‘á»‹nh cÃ³ pháº£i lÃ  Kubernetes command hay khÃ´ng"
            },
            tool: {
              type: ["string", "null"],
              description: "TÃªn tool cáº§n sá»­ dá»¥ng, null náº¿u khÃ´ng pháº£i K8s command",
              enum: ["kubectl_get", "kubectl_create", "kubectl_delete", "kubectl_describe", "kubectl_logs", "kubectl_scale", "kubectl_rollout", null]
            },
            arguments: {
              type: "object",
              description: "Arguments cho tool, object rá»—ng náº¿u khÃ´ng cÃ³",
              additionalProperties: true
            },
            explanation: {
              type: "string",
              description: "Giáº£i thÃ­ch ngáº¯n gá»n vá» phÃ¢n tÃ­ch"
            }
          },
          required: ["isK8sCommand", "tool", "arguments", "explanation"],
          additionalProperties: false
        }
      }
    };

    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini", // Sá»­ dá»¥ng model giÃ¡ ráº» cho phÃ¢n tÃ­ch
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      response_format: k8sAnalysisSchema,
      max_tokens: 500,
      temperature: 0.1, // Giáº£m nhiá»…u Ä‘á»ƒ cÃ³ káº¿t quáº£ nháº¥t quÃ¡n
    });

    const aiResponse = completion.choices[0]?.message?.content;
    if (!aiResponse) return null;

    console.log('OpenAI Structured Analysis Response:', aiResponse);

    // Vá»›i Structured Output, khÃ´ng cáº§n try/catch cho JSON.parse
    // Response Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº£m báº£o lÃ  valid JSON theo schema
    const analysis = JSON.parse(aiResponse);
    
    console.log('Parsed Analysis:', analysis);
    return analysis;

  } catch (error) {
    console.error('OpenAI Structured Output error:', error.message);
    return null;
  }
}

// API endpoint chÃ­nh
app.post('/api/chat', async (req, res) => {
  try {
    const userMessages = req.body.messages;
    const userPrompt = userMessages[userMessages.length - 1].content;

    console.log('User prompt:', userPrompt);

    // Kiá»ƒm tra MCP server connection
    if (!mcpServer.isServerConnected()) {
      console.log('MCP Server not connected, trying to reconnect...');
      const connected = await mcpServer.connect();
      
      if (!connected) {
        return res.status(503).json({ 
          message: { 
            content: 'âŒ MCP Server khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i Ä‘áº¿n 192.168.10.18.' 
          } 
        });
      }
    }

    // BÆ°á»›c 1: OpenAI phÃ¢n tÃ­ch prompt
    const analysis = await analyzeWithOpenAI(userPrompt);
    
    if (analysis && analysis.isK8sCommand) {
      console.log('ğŸ” AI Analysis:', JSON.stringify(analysis, null, 2));
      console.log('ğŸ“ Explanation:', analysis.explanation);
      
      // BÆ°á»›c 2: Gá»i MCP server vá»›i JSON-RPC format
      const result = await mcpServer.callTool(analysis.tool, analysis.arguments);
      
      if (result.result && result.result.content) {
        const content = result.result.content[0]?.text || 'Command executed successfully';
        res.json({ 
          message: { 
            content: `âœ… K8s Command Result:\nğŸ“‹ Analysis: ${analysis.explanation}\nğŸ“„ Output:\n${content}` 
          } 
        });
      } else {
        res.json({ 
          message: { 
            content: `âœ… Command executed successfully\nğŸ“‹ Analysis: ${analysis.explanation}` 
          } 
        });
      }
    } else {
      // Náº¿u khÃ´ng pháº£i K8s command, sá»­ dá»¥ng OpenAI cho chat thÃ´ng thÆ°á»ng
      try {
        const completion = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: userMessages.map(m => ({
            role: m.role,
            content: m.content
          })),
          max_tokens: 1000,
          temperature: 0.7,
        });

        const reply = completion.choices[0]?.message?.content;
        return res.json({ 
          message: { 
            content: reply || 'âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« OpenAI' 
          } 
        });
      } catch (err) {
        console.error('OpenAI Chat error:', err?.message || err);
        return res.status(502).json({ 
          message: { 
            content: 'âŒ Lá»—i gá»i OpenAI API' 
          } 
        });
      }
    }

  } catch (err) {
    console.error("Error:", err.message);
    res.status(500).json({ message: { content: "âŒ Lá»—i xá»­ lÃ½ request" } });
  }
});

// API Ä‘á»ƒ test trá»±c tiáº¿p
app.post('/api/test', async (req, res) => {
  try {
    const { prompt } = req.body;
    console.log('Test prompt:', prompt);
    
    const analysis = await analyzeWithOpenAI(prompt);
    res.json({ analysis });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// API Ä‘á»ƒ kiá»ƒm tra tráº¡ng thÃ¡i MCP server
app.get('/api/mcp/status', (req, res) => {
  res.json({
    connected: mcpServer.isServerConnected(),
    serverUrl: mcpServer.serverUrl,
    timestamp: new Date().toISOString()
  });
});

app.listen(8055, () => {
  console.log("âœ… Backend vá»›i OpenAI Structured Outputs + MCP Server remote cháº¡y táº¡i http://localhost:8055");
  console.log("ğŸŒ MCP Server URL: http://192.168.10.18:3000");
  console.log("ğŸ”Œ MCP SSE Endpoint: /sse");
  console.log("ğŸ“¬ MCP Messages Endpoint: /messages");
  console.log("ğŸ¤– AI Provider: OpenAI API vá»›i Structured Outputs");
  console.log("ğŸ“Š Features: JSON Schema validation, Type-safe responses");
  console.log("ğŸ”— API endpoints:");
  console.log("   - POST /api/chat - Chat vá»›i OpenAI Structured Outputs + MCP");
  console.log("   - GET /api/mcp/status - Kiá»ƒm tra MCP status");
  console.log("   - POST /api/test - Test phÃ¢n tÃ­ch prompt vá»›i Structured Output");
  console.log("âš ï¸  LÆ°u Ã½: Sá»­ dá»¥ng Ollama compatible endpoint táº¡i http://192.168.10.32:11434/v1");
  console.log("ğŸš€ MCP Server cáº§n cháº¡y vá»›i: ENABLE_UNSAFE_SSE_TRANSPORT=true");
});
